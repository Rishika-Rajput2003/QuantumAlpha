{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Initialize df with Sample Data - increase sample size to ensure enough data\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start=\"2023-01-01\", periods=200, freq=\"D\"),\n",
    "    \"Ticker\": [\"AAPL\"] * 100 + [\"MSFT\"] * 100,  # Equal distribution of tickers\n",
    "    \"Open\": np.random.uniform(100, 200, 200),\n",
    "    \"Close\": np.random.uniform(100, 200, 200),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "def calculate_indicators(df):\n",
    "    # Group by ticker to calculate indicators separately for each stock\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    for ticker, group in df.groupby('Ticker'):\n",
    "        group = group.copy()\n",
    "        group['MA_50'] = group['Close'].rolling(window=min(50, len(group))).mean()\n",
    "        group['RSI'] = calculate_rsi(group['Close'], period=min(14, len(group)-1))\n",
    "        group['MACD'] = calculate_macd(group['Close'])\n",
    "        result_df = pd.concat([result_df, group])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=period).mean()\n",
    "    avg_loss = loss.rolling(window=period).mean()\n",
    "    # Avoid division by zero\n",
    "    rs = avg_gain / avg_loss.replace(0, np.nan).fillna(0.00001)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(series, short_window=12, long_window=26, signal_window=9):\n",
    "    short_ema = series.ewm(span=short_window, adjust=False).mean()\n",
    "    long_ema = series.ewm(span=long_window, adjust=False).mean()\n",
    "    macd = short_ema - long_ema\n",
    "    signal = macd.ewm(span=signal_window, adjust=False).mean()\n",
    "    return macd - signal\n",
    "\n",
    "df = calculate_indicators(df)\n",
    "# Encode tickers using factorize to ensure consistent encoding\n",
    "df['Ticker Encoding'], ticker_mapping = pd.factorize(df['Ticker'])\n",
    "print(f\"Ticker mapping: {dict(enumerate(ticker_mapping))}\")\n",
    "\n",
    "# Step 2: Model Training\n",
    "def prepare_data(df, look_back=5):\n",
    "    # Calculate returns by ticker group\n",
    "    for ticker, group in df.groupby('Ticker'):\n",
    "        idx = group.index\n",
    "        df.loc[idx, 'Next Day Return'] = group['Close'].pct_change().shift(-1) * 100\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Error: No data available after calculating indicators and returns\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    features = ['Open', 'Close', 'MA_50', 'RSI', 'MACD']\n",
    "    X = []\n",
    "    y = []\n",
    "    ticker_encodings = []\n",
    "    tickers = []  # Store actual ticker symbols\n",
    "    \n",
    "    for ticker, ticker_df in df.groupby('Ticker'):\n",
    "        if len(ticker_df) <= look_back:\n",
    "            print(f\"Warning: Not enough data points for ticker {ticker}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Check if all features are available and not all NaN\n",
    "            if not all(feature in ticker_df.columns for feature in features):\n",
    "                print(f\"Warning: Missing features for ticker {ticker}. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            if ticker_df[features].isna().all().any():\n",
    "                print(f\"Warning: All NaN values in at least one feature for ticker {ticker}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            ticker_features = ticker_df[features].values\n",
    "            ticker_target = ticker_df['Next Day Return'].values\n",
    "            ticker_encoding = ticker_df['Ticker Encoding'].values[0]  # All encodings should be the same for a ticker\n",
    "            \n",
    "            for i in range(look_back, len(ticker_features)):\n",
    "                # Check for NaN values in this window\n",
    "                window = ticker_features[i-look_back:i]\n",
    "                if np.isnan(window).any() or np.isnan(ticker_target[i]):\n",
    "                    continue\n",
    "                    \n",
    "                X.append(window)\n",
    "                y.append(ticker_target[i])\n",
    "                ticker_encodings.append(ticker_encoding)\n",
    "                tickers.append(ticker)  # Append the actual ticker symbol\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing ticker {ticker}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"Error: No data points generated after filtering\")\n",
    "        return None, None, None, None\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    ticker_encodings = np.array(ticker_encodings)\n",
    "    tickers = np.array(tickers)\n",
    "    \n",
    "    print(f\"Prepared data for {np.unique(tickers)} with shapes X:{X.shape}, y:{y.shape}\")\n",
    "    \n",
    "    return X, y, ticker_encodings, tickers\n",
    "\n",
    "def train_lstm_model(X_train, y_train, epochs=1, batch_size=32):\n",
    "    # First check if we have valid data\n",
    "    if X_train is None or y_train is None:\n",
    "        print(\"Error: No training data available\")\n",
    "        return None\n",
    "        \n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        print(\"Error: Empty training data\")\n",
    "        return None\n",
    "    \n",
    "    # Verify that X_train has 3 dimensions: (samples, time steps, features)\n",
    "    if len(X_train.shape) != 3:\n",
    "        print(f\"Error: Expected 3D array for X_train, got shape {X_train.shape}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main logic with fallback for failure\n",
    "X, y, ticker_encodings, tickers = prepare_data(df)\n",
    "\n",
    "if X is not None and len(X) > 0:\n",
    "    model = train_lstm_model(X, y)\n",
    "    \n",
    "    if model is not None:\n",
    "        # Step 3: Portfolio Construction\n",
    "        def generate_signals_and_weights(predictions, ticker_encodings, tickers):\n",
    "            # Create a dictionary to map predictions to tickers\n",
    "            ticker_predictions = {}\n",
    "            \n",
    "            for i, (ticker, pred) in enumerate(zip(tickers, predictions)):\n",
    "                if ticker not in ticker_predictions:\n",
    "                    ticker_predictions[ticker] = []\n",
    "                ticker_predictions[ticker].append(pred)\n",
    "            \n",
    "            # Aggregate predictions by actual ticker\n",
    "            portfolio_data = []\n",
    "            \n",
    "            for ticker, preds in ticker_predictions.items():\n",
    "                avg_prediction = np.mean(preds)\n",
    "                signal = 'BUY' if avg_prediction > 0 else 'SELL' if avg_prediction < 0 else 'HOLD'\n",
    "                \n",
    "                # Get the ticker encoding for this ticker\n",
    "                ticker_encoding = ticker_encodings[np.where(tickers == ticker)[0][0]]\n",
    "                \n",
    "                portfolio_data.append({\n",
    "                    'Encoding': ticker_encoding,\n",
    "                    'Ticker': ticker,\n",
    "                    'Predicted Return': avg_prediction,\n",
    "                    'Signal': signal,\n",
    "                    'Prediction Count': len(preds)\n",
    "                })\n",
    "            \n",
    "            portfolio = pd.DataFrame(portfolio_data)\n",
    "            \n",
    "            if len(portfolio) == 0:\n",
    "                raise ValueError(\"No portfolio data generated\")\n",
    "            \n",
    "            # Calculate weights based on predicted returns\n",
    "            portfolio['Abs Return'] = np.abs(portfolio['Predicted Return'])\n",
    "            total_abs_return = portfolio['Abs Return'].sum()\n",
    "            \n",
    "            if total_abs_return > 0:\n",
    "                portfolio['Raw Weight'] = portfolio['Abs Return'] / total_abs_return\n",
    "                portfolio['Weight'] = np.where(\n",
    "                    portfolio['Signal'] == 'BUY', \n",
    "                    portfolio['Raw Weight'] * 100,\n",
    "                    np.where(\n",
    "                        portfolio['Signal'] == 'SELL',\n",
    "                        -portfolio['Raw Weight'] * 100,\n",
    "                        0\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # Default to equal weights if all predicted returns are 0\n",
    "                weight = 100 / len(portfolio)\n",
    "                portfolio['Weight'] = np.where(\n",
    "                    portfolio['Signal'] == 'BUY', weight,\n",
    "                    np.where(portfolio['Signal'] == 'SELL', -weight, 0)\n",
    "                )\n",
    "            \n",
    "            # Keep only necessary columns\n",
    "            portfolio = portfolio[['Encoding', 'Ticker', 'Predicted Return', 'Signal', 'Weight']]\n",
    "            \n",
    "            return portfolio\n",
    "\n",
    "        # Step 4: Backtesting\n",
    "        def backtest_portfolio(portfolio, df_prices, initial_capital=10000):\n",
    "            # Get the tickers, weights, and initial prices\n",
    "            tickers = portfolio['Ticker'].values  # Using actual tickers now\n",
    "            weights = portfolio['Weight'].values / 100\n",
    "            \n",
    "            # Make sure all tickers exist in df_prices\n",
    "            available_tickers = [ticker for ticker in tickers if ticker in df_prices.columns]\n",
    "            if len(available_tickers) != len(tickers):\n",
    "                print(f\"Warning: {len(tickers) - len(available_tickers)} tickers not found in price data\")\n",
    "                missing_tickers = set(tickers) - set(available_tickers)\n",
    "                print(f\"Missing tickers: {missing_tickers}\")\n",
    "                print(f\"Available columns in price data: {df_prices.columns.tolist()}\")\n",
    "                \n",
    "            # Filter portfolio to only include available tickers\n",
    "            available_indices = [i for i, ticker in enumerate(tickers) if ticker in df_prices.columns]\n",
    "            tickers = [tickers[i] for i in available_indices]\n",
    "            weights = [weights[i] for i in available_indices]\n",
    "            \n",
    "            if not tickers:\n",
    "                raise ValueError(\"No tickers from portfolio found in price data\")\n",
    "            \n",
    "            print(f\"Backtesting with tickers: {tickers} and weights: {weights}\")\n",
    "            \n",
    "            # Now get initial prices\n",
    "            initial_prices = df_prices.loc[df_prices.index[0], tickers].values\n",
    "            \n",
    "            portfolio_values = []  # To store the portfolio value for each day\n",
    "            \n",
    "            # Iterate through each day in the price data\n",
    "            for date, row in df_prices.iterrows():\n",
    "                portfolio_value = 0  # Initialize portfolio value for the day\n",
    "                \n",
    "                # Calculate the value of each position in the portfolio\n",
    "                for i, ticker in enumerate(tickers):\n",
    "                    shares = (initial_capital * weights[i]) / initial_prices[i]  # Number of shares\n",
    "                    price = row[ticker]  # Current price of the ticker\n",
    "                    \n",
    "                    if shares > 0:  # Long position\n",
    "                        portfolio_value += shares * price\n",
    "                    elif shares < 0:  # Short position\n",
    "                        position_value = (-shares) * (2 * initial_prices[i] - price)\n",
    "                        portfolio_value += position_value\n",
    "                    else:  # No position\n",
    "                        pass\n",
    "                \n",
    "                portfolio_values.append(portfolio_value)  # Append the daily portfolio value\n",
    "            \n",
    "            # Add the portfolio value to the price dataframe\n",
    "            df_prices['Portfolio Value'] = portfolio_values\n",
    "            return df_prices\n",
    "\n",
    "        # Step 5: Performance Evaluation (same as before)\n",
    "        def evaluate_performance(df_prices, initial_capital=10000, risk_free_rate=0.02):\n",
    "            df_prices['Portfolio Daily Return'] = df_prices['Portfolio Value'].pct_change()\n",
    "            df_prices['S&P 500 Daily Return'] = df_prices['S&P500'].pct_change()\n",
    "            \n",
    "            # Total Return\n",
    "            total_return = (df_prices['Portfolio Value'].iloc[-1] - initial_capital) / initial_capital * 100\n",
    "            \n",
    "            # CAGR\n",
    "            num_days = len(df_prices)\n",
    "            years = num_days / 252\n",
    "            CAGR = ((df_prices['Portfolio Value'].iloc[-1] / initial_capital) ** (1/years)) - 1\n",
    "            \n",
    "            # Max Drawdown\n",
    "            rolling_max = df_prices['Portfolio Value'].cummax()\n",
    "            drawdown = (df_prices['Portfolio Value'] - rolling_max) / rolling_max\n",
    "            max_drawdown = drawdown.min() * 100\n",
    "            \n",
    "            # Handling potential NaN values in performance metrics\n",
    "            portfolio_returns = df_prices['Portfolio Daily Return'].dropna()\n",
    "            \n",
    "            if len(portfolio_returns) > 0:\n",
    "                # Sharpe Ratio\n",
    "                sharpe_ratio = (portfolio_returns.mean() - risk_free_rate / 252) / portfolio_returns.std() if portfolio_returns.std() > 0 else 0\n",
    "                sharpe_ratio *= np.sqrt(252)\n",
    "                \n",
    "                # Sortino Ratio\n",
    "                downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "                sortino_ratio = (portfolio_returns.mean() - risk_free_rate / 252) / downside_returns.std() if len(downside_returns) > 0 and downside_returns.std() > 0 else 0\n",
    "                sortino_ratio *= np.sqrt(252)\n",
    "                \n",
    "                # Win Rate\n",
    "                win_rate = (portfolio_returns > 0).sum() / len(portfolio_returns) * 100\n",
    "            else:\n",
    "                sharpe_ratio, sortino_ratio, win_rate = 0, 0, 0\n",
    "            \n",
    "            # Alpha and Beta\n",
    "            benchmark_returns = df_prices['S&P 500 Daily Return'].dropna()\n",
    "            portfolio_returns = df_prices['Portfolio Daily Return'].dropna()\n",
    "            \n",
    "            if len(benchmark_returns) > 0 and len(portfolio_returns) > 0 and len(benchmark_returns) == len(portfolio_returns):\n",
    "                X = benchmark_returns.values\n",
    "                y = portfolio_returns.values\n",
    "                \n",
    "                if np.std(X) > 0:\n",
    "                    X_with_const = sm.add_constant(X)\n",
    "                    try:\n",
    "                        model = sm.OLS(y, X_with_const).fit()\n",
    "                        alpha, beta = model.params\n",
    "                        alpha *= 252  # Annualize alpha\n",
    "                    except:\n",
    "                        alpha, beta = 0, 1\n",
    "                else:\n",
    "                    alpha, beta = 0, 1\n",
    "            else:\n",
    "                alpha, beta = 0, 1\n",
    "            \n",
    "            # Print Performance Metrics\n",
    "            print(\"\\n📊 **FINAL PERFORMANCE REPORT** 📊\")\n",
    "            print(f\"✅ Total Return: {total_return:.2f}%\")\n",
    "            print(f\"✅ CAGR: {CAGR*100:.2f}% per year\")\n",
    "            print(f\"✅ Max Drawdown: {max_drawdown:.2f}%\")\n",
    "            print(f\"✅ Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "            print(f\"✅ Sortino Ratio: {sortino_ratio:.2f}\")\n",
    "            print(f\"✅ Win Rate: {win_rate:.2f}%\")\n",
    "            print(f\"✅ Alpha: {alpha*100:.2f}%\")\n",
    "            print(f\"✅ Beta: {beta:.2f}\")\n",
    "            \n",
    "            # Plot Portfolio vs S&P 500\n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.plot(df_prices.index, df_prices['Portfolio Value'], label=\"Portfolio\", color=\"blue\")\n",
    "            plt.plot(df_prices.index, df_prices['S&P500'] * (df_prices['Portfolio Value'].iloc[0] / df_prices['S&P500'].iloc[0]), \n",
    "                    label=\"S&P 500 (Normalized)\", color=\"red\", linestyle=\"dashed\")\n",
    "            plt.title(\"Portfolio vs S&P 500 Performance\")\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"Value ($)\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "\n",
    "        # Generate predictions and create portfolio\n",
    "        try:\n",
    "            predictions = model.predict(X).flatten()\n",
    "            portfolio = generate_signals_and_weights(predictions, ticker_encodings, tickers)\n",
    "            print(\"\\n📊 Portfolio Construction:\")\n",
    "            print(portfolio)\n",
    "            \n",
    "            # Backtesting data\n",
    "            data = {\n",
    "                \"Date\": pd.date_range(start=\"2023-06-14\", periods=20, freq=\"D\"),\n",
    "                \"AAPL\": [180, 182, 181, 185, 190, 192, 195, 194, 193, 192, 194, 195, 196, 198, 200, 202, 201, 200, 199, 198],\n",
    "                \"MSFT\": [330, 328, 326, 325, 322, 320, 315, 314, 313, 312, 310, 308, 307, 305, 304, 302, 301, 300, 298, 295],\n",
    "                \"S&P500\": [4400, 4410, 4420, 4430, 4440, 4450, 4460, 4470, 4480, 4490, \n",
    "                           4500, 4510, 4520, 4530, 4540, 4550, 4560, 4570, 4580, 4590]\n",
    "            }\n",
    "\n",
    "            df_prices = pd.DataFrame(data)\n",
    "            df_prices.set_index(\"Date\", inplace=True)\n",
    "\n",
    "            initial_capital = 10000\n",
    "            df_prices = backtest_portfolio(portfolio, df_prices, initial_capital)\n",
    "            evaluate_performance(df_prices, initial_capital)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during portfolio construction or backtesting: {e}\")\n",
    "    else:\n",
    "        print(\"Model training failed. Cannot proceed with portfolio construction and backtesting.\")\n",
    "else:\n",
    "    print(\"Data preparation failed. Cannot proceed with model training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
